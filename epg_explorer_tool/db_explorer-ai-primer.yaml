version: 1
updated: 2025-10-04

human:
  goals:
    - Make it trivial to inspect the Plex EPG DB the GUI depends on.
    - Quickly confirm which columns exist (newer vs older Plex variants).
    - Export quick samples to text when debugging.
  ways_of_working:
    - Prefer minimal, readable SQL.
    - Don’t mutate the DB: read-only queries only.
    - Keep CLI usage short and consistent with the GUI config.

purpose: >
  Small CLI to dump rows/columns from any table in the Plex EPG sqlite.
  Used to validate schemas (e.g., `user_thumb_url` vs `thumb_url`) and inspect
  fields the app relies on (title, poster URL, begins_at, year, genres, channel).

usage:
  basic:
    - cargo run --bin db_explorer metadata_items 10
    - cargo run --bin db_explorer media_items 20 --out dump.txt
  args:
    - <table>: string (required)
    - [limit]: number (default 5)
    - [--out file]: optional path to write output

db_resolution:
  order:
    - use the working copy at "db/plex_epg.db"
  mirrors_gui:
    - Same `config.json` as the GUI; optional `plex_db_source` keeps the working copy fresh.

field_reference:  # ← PRIME: where to find what the GUI needs
  posters:
    table: metadata_items AS m
    columns:
      - m.user_thumb_url (newer Plex) — may not exist on old DBs
      - m.thumb_url      (fallback)
    filter: m.metadata_type = 1 AND url column IS NOT NULL AND url <> ''
    sql_examples:
      - |
        -- Prefer user_thumb_url (newer DBs)
        SELECT m.title, m.user_thumb_url
        FROM metadata_items m
        WHERE m.metadata_type = 1
          AND m.user_thumb_url IS NOT NULL
          AND m.user_thumb_url <> ''
        LIMIT 20;
      - |
        -- Fallback if user_thumb_url missing
        SELECT m.title, m.thumb_url
        FROM metadata_items m
        WHERE m.metadata_type = 1
          AND m.thumb_url IS NOT NULL
          AND m.thumb_url <> ''
        LIMIT 20;
  schedule_time:
    join:
      - m.id ↔ mi.metadata_item_id
    columns:
      - mi.begins_at (Unix seconds)  # may be NULL; GUI falls back to added_at ordering in prep
      - m.added_at   (as secondary ordering in prep SQL)
    sql_example: |
      SELECT m.title, mi.begins_at, m.added_at
      FROM metadata_items m
      LEFT JOIN media_items mi ON mi.metadata_item_id = m.id
      WHERE m.metadata_type = 1
      ORDER BY COALESCE(mi.begins_at, m.added_at) ASC
      LIMIT 20;
  year_and_genres:
    table: metadata_items AS m
    columns:
      - m.year
      - m.tags_genre  # pipe-separated: "Sci-Fi|Drama"
    sql_example: |
      SELECT m.title, m.year, m.tags_genre
      FROM metadata_items m
      WHERE m.metadata_type = 1
      LIMIT 20;
  channel_from_extra_data:
    source:
      - media_items.extra_data (opaque string with key/value pairs)
    keys:
      - "at:channelCallSign"
      - "at:channelTitle"
    parsing:
      - Extract value between quotes for the given key; if there’s a leading code and a space,
        keep the right side (e.g., "001 BBC One" → "BBC One").
    sql_example: |
      SELECT mi.extra_data
      FROM media_items mi
      WHERE mi.extra_data IS NOT NULL AND mi.extra_data <> ''
      LIMIT 5;

db_inspection_workflows:
  confirm_poster_column:
    steps:
      - Try `SELECT user_thumb_url FROM metadata_items LIMIT 1;`
      - If error/NULLs, fall back to `thumb_url`.
  channel_field_presence:
    steps:
      - `SELECT COUNT(*) FROM media_items WHERE extra_data LIKE '%"at:channelCallSign"%';`
      - If 0, try `"at:channelTitle"`.
  sanity_check_time_range:
    steps:
      - `SELECT MIN(mi.begins_at), MAX(mi.begins_at) FROM media_items mi;`
      - Inspect sample titles around "now":
        - |
          SELECT m.title, mi.begins_at
          FROM metadata_items m
          JOIN media_items mi ON mi.metadata_item_id = m.id
          WHERE mi.begins_at BETWEEN strftime('%s','now') - 86400 AND strftime('%s','now') + 86400
          LIMIT 50;

ties_to_gui:
  prep.rs alignment:
    - Uses the same joins/filters as above.
    - Prefers `user_thumb_url`, falls back to `thumb_url`.
    - Orders by `COALESCE(mi.begins_at, m.added_at)`.
    - Parses `mi.extra_data` for channel.
    - Dedupes titles (case-insensitive) before sending `PrepMsg::Done(Vec<PrepItem>)`.
  mod.rs expectations:
    - Receives `PrepItem` and derives `small_key = base_cache_key + "__s"`.
    - Calls `find_any_by_key(small_key)` to reattach cached path if present.
    - Prefetches missing small posters; UI does lazy texture upload.

export_format:
  stdout:
    - Header: `--- Table: <table> ---`
    - Columns: `Columns: ["c1", "c2", ...]`
    - Rows: Rust Vec-format per row, with typed values:
      - NULL, integer, real, UTF-8 text, "<BLOB>"
  file:
    - Use `--out path` to write the same text to a file.

safety_notes:
  - Read-only access: do not issue UPDATE/DELETE; the tool never writes to the DB.
  - Beware of tables with large blobs; limit your queries.
  - Respect Windows paths from `config.json`.

quick_commands:
  - Posters sample (new): cargo run --bin db_explorer metadata_items 10
  - Media extras sample:  cargo run --bin db_explorer media_items 5
  - Export:               cargo run --bin db_explorer metadata_items 50 --out posters.txt
